# -*- coding: utf-8 -*-
"""PatRecLab03_Part2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V1kqK3KiICfIfVdxyFxernQ8zjYDPNER
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# Helper functions to read fused, mel, and chromagram
def read_fused_spectrogram(spectrogram_file):
    spectrogram = np.load(spectrogram_file)
    return spectrogram.T


def read_mel_spectrogram(spectrogram_file):
    spectrogram = np.load(spectrogram_file)[:128]
    return spectrogram.T

    
def read_chromagram(spectrogram_file):
    spectrogram = np.load(spectrogram_file)[128:]
    return spectrogram.T

def get_files_labels(txt,emotion_type):
    with open(txt, 'r') as fd:
        lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]
        files, labels = [], []
        for l in lines:
            if emotion_type == "Valence":
                label = float(l[1])
            elif emotion_type == "Energy":
                label = float(l[2]) 
            elif emotion_type == "Danceability":
                label = float(l[3])
            elif emotion_type == "All":
                label = [float(l[1]),float(l[2]),float(l[3])]
            else: raise TypeError("Wrong emotion type!")
            if not label:
                continue
            # Kaggle automatically unzips the npy.gz format so this hack is needed
            _id = l[0]
            npy_file = '{}.fused.full.npy'.format(_id)
            files.append(npy_file)
            labels.append(label)
        return files, labels

"""### Βήμα 8: Εκτίμηση συναισθήματος-συμπεριφοράς με παλινδρόμηση"""

import copy
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import Dataset
from torch.utils.data import SubsetRandomSampler, DataLoader
import re

# TODO: Comment on how the train and validation splits are created.
# TODO: It's useful to set the seed when debugging but when experimenting ALWAYS set seed=None. Why?
def torch_train_val_test_split(
        dataset, batch_train, batch_eval, batch_test,
        val_size=.15, test_size = .15, shuffle=True, seed=None):
    
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    test_split = int(np.floor(test_size * dataset_size))

    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
        
    val_indices = indices[:val_split]
    test_indices = indices[val_split:(val_split+test_split)]
    train_indices = indices[(val_split+test_split):]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)
    test_sampler = SubsetRandomSampler(test_indices)

    train_loader = DataLoader(dataset,
                              batch_size=batch_train,
                              sampler=train_sampler)
    val_loader = DataLoader(dataset,
                            batch_size=batch_eval,
                            sampler=val_sampler)
    test_loader = DataLoader(dataset,
                            batch_size=batch_test,
                            sampler=test_sampler)
    
    return train_loader, val_loader, test_loader


# TODO: Comment on why padding is needed
class PaddingTransform(object):
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[:self.max_length]
        
        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1

# Pytorch Dataset Class for creating the dataset
class MultitaskDataset(Dataset):
    def __init__(self, path, max_length=-1, read_spec_fn=read_fused_spectrogram, emotion_type = "Valence"):
        self.index = os.path.join(path, "train_labels.txt")
        self.files, labels = get_files_labels(self.index,emotion_type)
        self.feats = [read_spec_fn(os.path.join(path+"train", f)) for f in self.files] # lista apo arrays opoy to kathe ena einai to mel / chromogram
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        if isinstance(labels, (list, tuple)):
            self.labels = np.array(labels)

    def __getitem__(self, item):
        # TODO: Inspect output and comment on how the output is formatted
        l = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l

    def __len__(self):
        return len(self.labels)

def fit(model, train_loader, validation_loader, loss_fn, num_epochs, patience = 10, batch_size = 32, L2 = 0, earlyStopping = True, nn_type = "LSTM"):
    
    # Adam Optimizer
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=L2)
    
    min_val_loss = np.Inf
    
    early_stop = False

    for epoch in range(num_epochs):

        model.train()
        train_loss = 0
        for batch, labels, lengths in train_loader:
            if torch.cuda.is_available():
                batch = batch.cuda()
                labels = labels.cuda()
                lengths = lengths.cuda()
            # Clear gradients
            optimizer.zero_grad()

            # Calculate output
            if nn_type == "LSTM":
                output = model(batch,lengths)
            else:
                output = model(batch)
            # Calculate loss
            loss = loss_fn(np.squeeze(output), labels)
            
            # Calculating gradients
            loss.backward()

            # Update parameters
            optimizer.step()
        
            train_loss += loss.item()
        train_loss /= len(train_loader)

        model.eval()
        valid_loss = 0
        with torch.no_grad():
            for batch, labels, lengths in validation_loader:
                if torch.cuda.is_available():
                        batch = batch.cuda()
                        labels = labels.cuda()
                        lengths = lengths.cuda()
                # Calculate output
                if nn_type == "LSTM":
                    output = model(batch,lengths)
                else:
                    output = model(batch)
                    
                # Calculate MSE loss
                loss = loss_fn(np.squeeze(output), labels)
                valid_loss += loss.item()
        valid_loss /= len(validation_loader)

        # Check for use of earlyStopping
        if earlyStopping:
            if valid_loss < min_val_loss: # improvement
                torch.save(model.state_dict(),"best.pt")
                epochs_no_improve = 0
                min_val_loss = valid_loss
            else: # no improvement
                epochs_no_improve +=1 
            if epochs_no_improve == patience:
                early_stop = True

        print("Epoch: {}/{}".format(epoch+1,num_epochs), "...", "\033[1mTraining loss: {:.6f}\033[0m".format(train_loss), "...", "\033[1mValidation loss: {:.6f}\033[0m".format(valid_loss))

        # Check early stopping condition
        if early_stop and earlyStopping:
            print('Early stopping!')
            print('Stopped')
            break

    return

from scipy.stats import spearmanr

def find_spearman_correlation(model, data_loader,nn_type="LSTM"):
    model.load_state_dict(torch.load("best.pt"))
    model.eval()
    targets, predictions = [], []
    with torch.no_grad():
            for batch, labels, lengths in data_loader:
                if torch.cuda.is_available():
                        batch = batch.cuda()
                        labels = labels.cuda()
                        lengths = lengths.cuda()
                if nn_type == "LSTM":
                    output = model(batch,lengths)
                else:
                    output = model(batch)
                predictions.extend(output.cpu().numpy())
                targets.extend(labels.cpu().numpy())
    spearman_correlation = spearmanr(predictions,targets).correlation
    return abs(spearman_correlation)

"""#### (a)"""

import torch
import torch.nn as nn

class BasicLSTM(nn.Module):
    
    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, bidirectional=False, dropout = 0):

        super(BasicLSTM, self).__init__()
        self.bidirectional = bidirectional                                       # Parameter that defines if our model is unidirectional or bidiretional (bidirectional if True)
        self.feature_size = hidden_dim*2 if self.bidirectional else hidden_dim   # Feature size

        self.hidden_dim = hidden_dim         # Hidden dimensions
        self.num_layers = num_layers         # Number of hidden layers
        
        self.lstm    = nn.LSTM(input_dim, hidden_dim, num_layers, dropout = dropout, bidirectional=self.bidirectional, batch_first=True)  # Define LSTM model
        self.linear  = nn.Linear(self.feature_size, output_dim) # Apply linear transformation before output

    def forward(self, x, lengths):

        h0 = torch.zeros(self.num_layers*(1+int(self.bidirectional)), x.size(0), self.hidden_dim).double().requires_grad_()           # Initialize hidden state with zeros
        c0 = torch.zeros(self.num_layers*(1+int(self.bidirectional)), x.size(0), self.hidden_dim).double().requires_grad_()           # Initialize cell state
        if torch.cuda.is_available():
            h0 = h0.cuda()
            c0 = c0.cuda()
        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
        last_outputs = self.last_timestep(out,lengths,self.bidirectional)
        last_outputs = self.linear(last_outputs)
        return last_outputs

    def last_timestep(self, outputs, lengths, bidirectional=False):

        if bidirectional:
            forward, backward = self.split_directions(outputs)
            last_forward = self.last_by_index(forward, lengths)
            last_backward = backward[:, 0, :]
            # Concatenate and return - maybe add more functionalities like average
            return torch.cat((last_forward, last_backward), dim=-1)

        else:
            return self.last_by_index(outputs, lengths)

    @staticmethod
    def split_directions(outputs):

        direction_size = int(outputs.size(-1) / 2)
        forward = outputs[:, :, :direction_size]
        backward = outputs[:, :, direction_size:]
        return forward, backward

    @staticmethod
    def last_by_index(outputs, lengths):

        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),
                                               outputs.size(2)).unsqueeze(1)
        return outputs.gather(1, idx).squeeze()

import torch
import torch.nn as nn

class ConvNet(nn.Module):
    
    def __init__(self, in_channels=1, out_channels=32, in_features=6144, output_dim=1):
        
        super(ConvNet,self).__init__()
        self.conv1 = nn.Sequential(                                                         # Define a sequential architecture
            nn.Conv2d(in_channels, out_channels*1, kernel_size=3,padding=1),                # 1st convolutional layer
            nn.BatchNorm2d(out_channels*1),                                                 # 1st Batch normalization layer
            nn.ReLU(),                                                                      # Relu activation function
            nn.MaxPool2d(kernel_size=2))                                                    # Max Pooling with kernel size = 2
        
        self.conv2 = nn.Sequential(                                                         # Define a sequential layer
            nn.Conv2d(out_channels*1, out_channels*2, kernel_size=3,padding=1),             # 2nd convolutional layer
            nn.BatchNorm2d(out_channels*2),                                                 # 2nd Batch normalization layer
            nn.ReLU(),                                                                      # Relu activation function
            nn.MaxPool2d(kernel_size=2))                                                    # Max Pooling layer with kernel size = 2
        
        self.conv3 = nn.Sequential(                                                         # Define a sequential architecture
            nn.Conv2d(out_channels*2, out_channels*3, kernel_size=3,padding=1),             # 3rd convolutional layer
            nn.BatchNorm2d(out_channels*3),                                                 # 3rd Batch normalization layer
            nn.ReLU(),                                                                      # Relu activation function
            nn.MaxPool2d(kernel_size=2))                                                    # Max Pooling with kernel size = 2
        
        self.conv4 = nn.Sequential(                                                         # Define a sequential architecture
            nn.Conv2d(out_channels*3, out_channels*4, kernel_size=3, stride=1, padding=1),  # 4th convolutional layer
            nn.BatchNorm2d(out_channels*4),                                                 # 4th Batch normalization layer
            nn.ReLU(),                                                                      # Max Pooling with kernel size = 2
            nn.MaxPool2d(kernel_size=2))            
        
        self.linear1 = nn.Linear(in_features,1024)                                          # 1st linear layer
        self.linear2 = nn.Linear(1024,512)                                                  # 2nd linear layer
        self.linear3 = nn.Linear(512,output_dim)                                            # 3rd linear layer

    def forward(self, x):
        
        x = x.view(x.size(0), 1, x.size(1), x.size(2))
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        
        x = x.reshape(x.size(0),-1)
        x = self.linear1(x)
        x = self.linear2(x)
        x = self.linear3(x)
        return x

"""### (b) Valence"""

# Create multitask dataset for valence estimation
multitask_valence = MultitaskDataset(
         '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
         max_length=-1,
         read_spec_fn=read_mel_spectrogram,
         emotion_type="Valence")
    
train_loader_multitask_valence, val_loader_multitask_valence, test_loader_multitask_valence = torch_train_val_test_split(multitask_valence, 32 ,32, 32, val_size=.15, test_size=.15)

# Create LSTM
input_dim = 128     # input dimension
hidden_dim = 256    # hidden layer dimension
layer_dim = 2       # number of hidden layers
output_dim = 1      # output dimension

# Number of epochs
num_epochs = 100

# MSE Entropy Loss 
loss_fn = nn.MSELoss()

# Define model
model = BasicLSTM(input_dim, hidden_dim, layer_dim, output_dim, bidirectional=True, dropout=0.2).double()

if torch.cuda.is_available():
    model = model.cuda()
    
# Fit
fit(model, train_loader_multitask_valence, val_loader_multitask_valence, loss_fn, num_epochs, L2 = 0, earlyStopping=True)

val_spear_corr_lstm_valence = find_spearman_correlation(model, val_loader_multitask_valence)                # Find Spearman Correlation for validation data
test_spear_corr_lstm_valence = find_spearman_correlation(model, test_loader_multitask_valence)              # Find Spearman Correlation for test data

print("Spearman correlation of the best model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(val_spear_corr_lstm_valence,3)))
print("Spearman correlation of the best model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(test_spear_corr_lstm_valence,3)))

# Create ConvNet
in_channels = 1     # number of channels
out_channels = 32   # hidden layer dimension
in_features = 6144  # number of features
output_dim = 1      # output dimension

# Number of epochs
num_epochs = 100

# MSE Entropy Loss 
loss_fn = nn.MSELoss()

# Define model 
model = ConvNet(in_channels, out_channels, in_features, output_dim).double()

if torch.cuda.is_available():
    model = model.cuda()

# Fit
fit(model, train_loader_multitask_valence, val_loader_multitask_valence, loss_fn, num_epochs, L2 = 0, earlyStopping=True, nn_type="CNN")

val_spear_corr_conv_valence = find_spearman_correlation(model, val_loader_multitask_valence, nn_type="CNN")              # Find Spearman Correlation for validation data
test_spear_corr_conv_valence = find_spearman_correlation(model, test_loader_multitask_valence, nn_type="CNN")            # Find Spearman Correlation for test data

print("Spearman correlation of the best model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(val_spear_corr_conv_valence,3)))
print("Spearman correlation of the best model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(test_spear_corr_conv_valence,3)))

"""### (c) Energy"""

# Create multitask dataset for energy estimation
multitask_energy = MultitaskDataset(
         '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
         max_length=-1,
         read_spec_fn=read_mel_spectrogram,
         emotion_type="Energy")
    
train_loader_multitask_energy, val_loader_multitask_energy, test_loader_multitask_energy = torch_train_val_test_split(multitask_energy, 32 ,32, 32, val_size=.15, test_size=.15)

# Create LSTM
input_dim = 128     # input dimension
hidden_dim = 256    # hidden layer dimension
layer_dim = 2       # number of hidden layers
output_dim = 1      # output dimension

# Number of epochs
num_epochs = 100

# MSE Entropy Loss 
loss_fn = nn.MSELoss()

# Define model
model = BasicLSTM(input_dim, hidden_dim, layer_dim, output_dim, bidirectional=True, dropout=0.2).double()

if torch.cuda.is_available():
    model = model.cuda()
    
# Fit
fit(model, train_loader_multitask_energy, val_loader_multitask_energy, loss_fn, num_epochs, L2 = 0, earlyStopping=True)

val_spear_corr_lstm_energy = find_spearman_correlation(model, val_loader_multitask_energy)                  # Find Spearman Correlation for validation data
test_spear_corr_lstm_energy = find_spearman_correlation(model, test_loader_multitask_energy)                # Find Spearman Correlation for test data

print("Spearman correlation of the best model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(val_spear_corr_lstm_energy,3)))
print("Spearman correlation of the best model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(test_spear_corr_lstm_energy,3)))

# Create ConvNet
in_channels = 1     # number of channels
out_channels = 32   # hidden layer dimension
in_features = 6144  # number of features
output_dim = 1      # output dimension

# Number of epochs
num_epochs = 100

# MSE Entropy Loss 
loss_fn = nn.MSELoss()

# Define model
model = ConvNet(in_channels, out_channels, in_features, output_dim).double()

if torch.cuda.is_available():
    model = model.cuda()

# Fit
fit(model, train_loader_multitask_energy, val_loader_multitask_energy, loss_fn, num_epochs, L2 = 0, earlyStopping=True, nn_type="CNN")

val_spear_corr_conv_energy = find_spearman_correlation(model, val_loader_multitask_energy, nn_type="CNN")                   # Find Spearman Correlation for validation data
test_spear_corr_conv_energy = find_spearman_correlation(model, test_loader_multitask_energy, nn_type="CNN")                 # Find Spearman Correlation for test data

print("Spearman correlation of the best model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(val_spear_corr_conv_energy,3)))
print("Spearman correlation of the best model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(test_spear_corr_conv_energy,3)))

"""### (d) Danceability"""

# Create multitask dataset for danceability estimation
multitask_danceability = MultitaskDataset(
         '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
         max_length=-1,
         read_spec_fn=read_mel_spectrogram,
         emotion_type="Danceability")
    
train_loader_multitask_danceability, val_loader_multitask_danceability, test_loader_multitask_danceability = torch_train_val_test_split(multitask_danceability, 32 ,32, 32, val_size=.15, test_size=.15)

# Create LSTM
input_dim = 128     # input dimension
hidden_dim = 256    # hidden layer dimension
layer_dim = 2       # number of hidden layers
output_dim = 1      # output dimension

# Number of epochs
num_epochs = 100

# MSE Entropy Loss 
loss_fn = nn.MSELoss()

# Define model
model = BasicLSTM(input_dim, hidden_dim, layer_dim, output_dim, bidirectional=True, dropout=0.2).double()

if torch.cuda.is_available():
    model = model.cuda()
    
# Fit
fit(model, train_loader_multitask_danceability, val_loader_multitask_danceability, loss_fn, num_epochs, L2 = 0, earlyStopping=True)

val_spear_corr_lstm_danceability = find_spearman_correlation(model, val_loader_multitask_danceability)            # Find Spearman Correlation for validation data
test_spear_corr_lstm_danceability = find_spearman_correlation(model, test_loader_multitask_danceability)          # Find Spearman Correlation for test data

print("Spearman correlation of the best model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(val_spear_corr_lstm_danceability,3)))
print("Spearman correlation of the best model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(test_spear_corr_lstm_danceability,3)))

# Create ConvNet
in_channels = 1     # number of channels
out_channels = 32   # hidden layer dimension
in_features = 6144  # number of features
output_dim = 1      # output dimension

# Number of epochs
num_epochs = 100

# MSE Entropy Loss 
loss_fn = nn.MSELoss()

# Define model
model = ConvNet(in_channels, out_channels, in_features, output_dim).double()

if torch.cuda.is_available():
    model = model.cuda()

# Fit
fit(model, train_loader_multitask_danceability, val_loader_multitask_danceability, loss_fn, num_epochs, L2 = 0, earlyStopping=True, nn_type="CNN")

val_spear_corr_conv_danceability = find_spearman_correlation(model, val_loader_multitask_danceability, nn_type="CNN")             # Find Spearman Correlation for validation data
test_spear_corr_conv_danceability = find_spearman_correlation(model, test_loader_multitask_danceability, nn_type="CNN")           # Find Spearman Correlation for test data

print("Spearman correlation of the best model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(val_spear_corr_conv_danceability,3)))
print("Spearman correlation of the best model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(test_spear_corr_conv_danceability,3)))

"""### (e)"""

# Calculate Mean Spearman Correlation for LSTM
mean_val_spear_corr_lstm =  (val_spear_corr_lstm_valence + val_spear_corr_lstm_energy + val_spear_corr_lstm_danceability) / 3
mean_test_spear_corr_lstm = (test_spear_corr_lstm_valence + test_spear_corr_lstm_energy + test_spear_corr_lstm_danceability) / 3

print("Mean spearman correlation of LSTM model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(mean_val_spear_corr_lstm,3)))
print("Mean spearman correlation of LSTM model on \033[1mtest data\033[0m is \033[1m{}\033[0m\n".format(np.round(mean_test_spear_corr_lstm,3)))

# Calculate Mean Spearman Correlation for CNN
mean_val_spear_corr_conv = (val_spear_corr_conv_valence + val_spear_corr_conv_energy + val_spear_corr_conv_danceability) / 3
mean_test_spear_corr_conv = (test_spear_corr_conv_valence + test_spear_corr_conv_energy + test_spear_corr_conv_danceability) / 3

print("Mean spearman correlation of CNN model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(mean_val_spear_corr_conv,3)))
print("Mean spearman correlation of CNN model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(mean_test_spear_corr_conv,3)))

"""#### (f)"""

# Create multitask dataset for emotion_type = "All"
multitask_all = MultitaskDataset(
         '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/',
         max_length=-1,
         read_spec_fn=read_mel_spectrogram,
         emotion_type="All")
    
train_loader_multitask_all, val_loader_multitask_all, test_loader_multitask_all = torch_train_val_test_split(multitask_all, 32 ,32, 32, val_size=.15, test_size=.15)

"""### Βήμα 9α: Μεταφορά γνώσης (Transfer Learning)"""

# Combine similar classes and remove underrepresented classes
class_mapping = {
    'Rock': 'Rock',
    'Psych-Rock': 'Rock',
    'Indie-Rock': None,
    'Post-Rock': 'Rock',
    'Psych-Folk': 'Folk',
    'Folk': 'Folk',
    'Metal': 'Metal',
    'Punk': 'Metal',
    'Post-Punk': None,
    'Trip-Hop': 'Trip-Hop',
    'Pop': 'Pop',
    'Electronic': 'Electronic',
    'Hip-Hop': 'Hip-Hop',
    'Classical': 'Classical',
    'Blues': 'Blues',
    'Chiptune': 'Electronic',
    'Jazz': 'Jazz',
    'Soundtrack': None,
    'International': None,
    'Old-Time': None
}

def get_files_labels(txt, class_mapping=None):
    with open(txt, 'r') as fd:
        lines = [l.rstrip().split('\t') for l in fd.readlines()[1:]]
        files, labels = [], []
        for l in lines:
            label = l[1]
            if class_mapping:
                label = class_mapping[l[1]]
            if not label:
                continue
            # Kaggle automatically unzips the npy.gz format so this hack is needed
            _id = l[0].split('.')[0]
            npy_file = '{}.fused.full.npy'.format(_id)
            files.append(npy_file)
            labels.append(label)
        return files, labels
    
# TODO: Comment on how the train and validation splits are created.
# TODO: It's useful to set the seed when debugging but when experimenting ALWAYS set seed=None. Why?
def torch_train_val_split(
        dataset, batch_train, batch_eval,
        val_size=.2, shuffle=True, seed=None):
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    train_indices = indices[val_split:]
    val_indices = indices[:val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    train_loader = DataLoader(dataset,
                              batch_size=batch_train,
                              sampler=train_sampler)
    val_loader = DataLoader(dataset,
                            batch_size=batch_eval,
                            sampler=val_sampler)
    return train_loader, val_loader


class LabelTransformer(LabelEncoder):
    def inverse(self, y):
        try:
            return super(LabelTransformer, self).inverse_transform(y)
        except:
            return super(LabelTransformer, self).inverse_transform([y])

    def transform(self, y):
        try:
            return super(LabelTransformer, self).transform(y)
        except:
            return super(LabelTransformer, self).transform([y])


# TODO: Comment on why padding is needed
class PaddingTransform(object):
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[:self.max_length]
        
        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1

# Pytorch Dataset Class for creating the dataset
class SpectrogramDataset(Dataset):
    def __init__(self, path, class_mapping=None, train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):
        t = 'train' if train else 'test'
        p = os.path.join(path, t)
        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, labels = get_files_labels(self.index, class_mapping)
        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files] # lista apo arrays opoy to kathe ena einai to mel / chromogram
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.label_transformer = LabelTransformer()
        if isinstance(labels, (list, tuple)):
            self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')
    def __getitem__(self, item):
        # TODO: Inspect output and comment on how the output is formatted
        l = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l

    def __len__(self):
        return len(self.labels)

beat_mel_specs = SpectrogramDataset(
         '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/',
         train=True,
         class_mapping=class_mapping,
         max_length=-1,
         read_spec_fn=read_mel_spectrogram)
    
train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_specs, 32 ,32, val_size=.33)

# Create ConvNet
in_channels = 1     # number of channels
out_channels = 32   # hidden layer dimension
in_features = 8192  # number of features
output_dim = 10     # output dimension

# Number of epochs
num_epochs = 100

# Cross Entropy Loss 
loss_fn = nn.CrossEntropyLoss()

# Define model
model = ConvNet(in_channels, out_channels, in_features, output_dim).double()

if torch.cuda.is_available():
    model = model.cuda()

# Fit
fit(model, train_loader_beat_mel, val_loader_beat_mel, loss_fn, num_epochs, L2 = 0, earlyStopping=True, nn_type="CNN")

model.load_state_dict(torch.load('best.pt'))                # Load best model
model.linear1 = nn.Linear(6144,1024)                        # Change 1st linear layer
model.linear2 = nn.Linear(1024,512)                         # Change 2nd linear layer
model.linear3 = nn.Linear(512,1)                            # Change 3rd linear layer
model = model.double()

if torch.cuda.is_available():
    model = model.cuda()

# Number of epochs
num_epochs = 20

# MSE Entropy Loss 
loss_fn = nn.MSELoss()

# Fit
fit(model, train_loader_multitask_energy, val_loader_multitask_energy, loss_fn, num_epochs, L2 = 0, earlyStopping=True, nn_type="CNN")

transfer_val_spear_corr = find_spearman_correlation(model, val_loader_multitask_energy, nn_type="CNN")                # Find Spearman Correlation for validation data
transfer_test_spear_corr = find_spearman_correlation(model, test_loader_multitask_energy,nn_type="CNN")               # Find Spearman Correlation for test data

print("Spearman correlation of the best transfer learning model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m".format(np.round(transfer_val_spear_corr,3)))
print("Spearman correlation of the best transfer learning model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(transfer_test_spear_corr,3)))

"""### Βήμα 9β: Εκπαίδευση σε πολλά προβλήματα (Multitask Learning)"""

def multitask_fit(model, train_loader, validation_loader, num_epochs, patience = 10, batch_size = 32, L2 = 0, earlyStopping = True, pack_padded_sequence = False, nn_type = "LSTM"):
    
    # MSE Entropy Loss 
    loss_fn = nn.MSELoss()

    # Adam Optimizer
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=L2)
    
    min_val_loss = np.Inf
    
    early_stop = False

    for epoch in range(num_epochs):

        model.train()
        train_loss = 0
        if pack_padded_sequence:
            packed_batches, packed_labels, packed_lengths = pack_pad(batch_size)
            train_loader = list(zip(packed_batches, packed_labels, packed_lengths))
        for batch, labels, lengths in train_loader:
            if torch.cuda.is_available():
                batch = batch.cuda()
                labels = labels.cuda()
                lengths = lengths.cuda()
            # Clear gradients
            optimizer.zero_grad()

            # Calculate output
            if nn_type == "LSTM":
                output = model(batch,lengths)
            else:
                output = model(batch)
            
            output_valence = output[:,0]
            output_energy = output[:,1]
            output_danceability = output[:,2]
            
            # Calculate MSE losses
            loss_valence = loss_fn(np.squeeze(output_valence), labels[:,0])
            loss_energy = loss_fn(np.squeeze(output_energy), labels[:,1])
            loss_danceability = loss_fn(np.squeeze(output_danceability), labels[:,2])
            
            loss = loss_valence + loss_energy + loss_danceability
            
            # Calculating gradients
            loss.backward()

            # Update parameters
            optimizer.step()
        
            train_loss += loss.item()
        train_loss /= len(train_loader)

        model.eval()
        valid_loss = 0
        with torch.no_grad():
            for batch, labels, lengths in validation_loader:
                if torch.cuda.is_available():
                        batch = batch.cuda()
                        labels = labels.cuda()
                        lengths = lengths.cuda()
                # Calculate output
                if nn_type == "LSTM":
                    output = model(batch,lengths)
                else:
                    output = model(batch)
                    
                # Calculate MSE losses
                output_valence = output[:,0]
                output_energy = output[:,1]
                output_danceability = output[:,2]
            
                # Calculate MSE losses
                loss_valence = loss_fn(np.squeeze(output_valence), labels[:,0])
                loss_energy = loss_fn(np.squeeze(output_energy), labels[:,1])
                loss_danceability = loss_fn(np.squeeze(output_danceability), labels[:,2])
            
                loss = loss_valence + loss_energy + loss_danceability
                valid_loss += loss.item()
        valid_loss /= len(validation_loader)

        # Check for use of earlyStopping
        if earlyStopping:
            if valid_loss < min_val_loss: # improvement
                torch.save(model.state_dict(),"best.pt")
                epochs_no_improve = 0
                min_val_loss = valid_loss
            else: # no improvement
                epochs_no_improve +=1 
            if epochs_no_improve == patience:
                early_stop = True

        print("Epoch: {}/{}".format(epoch+1,num_epochs), "...", "\033[1mTraining loss: {:.6f}\033[0m".format(train_loss), "...", "\033[1mValidation loss: {:.6f}\033[0m".format(valid_loss))

        # Check early stopping condition
        if early_stop and earlyStopping:
            print('Early stopping!')
            print('Stopped')
            break

    return

from scipy.stats import spearmanr

def find_multitask_spearman_correlation(model, data_loader,nn_type="LSTM"):
    model.load_state_dict(torch.load("best.pt"))
    model.eval()
    correct = 0
    n_samples = 0
    targets_valence, targets_energy, targets_danceability, predictions_valence, predictions_energy, predictions_danceability = [],[],[],[],[],[]
    with torch.no_grad():
            for batch, labels, lengths in data_loader:
                if torch.cuda.is_available():
                        batch = batch.cuda()
                        labels = labels.cuda()
                        lengths = lengths.cuda()
                if nn_type == "LSTM":
                    output = model(batch,lengths)
                else:
                    output = model(batch)

                
                predictions_valence.extend(output[:,0].cpu().numpy())
                predictions_energy.extend(output[:,1].cpu().numpy())
                predictions_danceability.extend(output[:,2].cpu().numpy())
                
                targets_valence.extend(labels[:,0].cpu().numpy())
                targets_energy.extend(labels[:,1].cpu().numpy())
                targets_danceability.extend(labels[:,2].cpu().numpy())
    
    spearman_correlation_valence = spearmanr(predictions_valence,targets_valence).correlation                               # Find Spearman Correlation for valence
    spearman_correlation_energy = spearmanr(predictions_energy,targets_energy).correlation                                  # Find Spearman Correlation for energy
    spearman_correlation_danceability = spearmanr(predictions_danceability,targets_danceability).correlation                # Find Spearman Correlation for danceability
    
    print("Spearman correlation for \033[1m Valence \033[0m is \033[1m{}\033[0m".format(np.round(spearman_correlation_valence,3)))
    print("Spearman correlation for \033[1m Energy \033[0m is \033[1m{}\033[0m".format(np.round(spearman_correlation_energy,3)))
    print("Spearman correlation for \033[1m Danceability \033[0m is \033[1m{}\033[0m".format(np.round(spearman_correlation_danceability,3)))

    return ((abs(spearman_correlation_valence)+abs(spearman_correlation_energy)+abs(spearman_correlation_danceability))/3)    # Return Mean Spearman Correlation

# Create ConvNet
in_channels = 1     # number of channels
out_channels = 40   # hidden layer dimension
in_features = 7680  # number of features
output_dim = 3      # output dimension

# Number of epochs
num_epochs = 100

# Define model
model = ConvNet(in_channels, out_channels, in_features, output_dim).double()

if torch.cuda.is_available():
    model = model.cuda()

# Fit
multitask_fit(model, train_loader_multitask_all, val_loader_multitask_all, num_epochs, L2 = 0, earlyStopping=True, nn_type="CNN")

val_spearman_correlation = find_multitask_spearman_correlation(model, val_loader_multitask_all, nn_type="CNN")                # Find Spearman Correlation for validation data
print("Mean spearman correlation of the best model on \033[1mvalidation data\033[0m is \033[1m{}\033[0m\n".format(np.round(val_spearman_correlation,3)))

test_spearman_correlation = find_multitask_spearman_correlation(model, test_loader_multitask_all, nn_type="CNN")              # Find Spearman Correlation for test data
print("Mean spearman correlation of the best model on \033[1mtest data\033[0m is \033[1m{}\033[0m".format(np.round(test_spearman_correlation,3)))